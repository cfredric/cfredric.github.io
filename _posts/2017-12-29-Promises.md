---
layout: post
title: The Nature of Promises
---

I want to take you down the journey I went down when I initially learned about
JavaScript `Promise`s for work. I happened to be teaching myself Haskell at the
time for fun, and I was determined to not be intimidated by these infamous
"monad" things. There are already enough monad tutorials, but I aim to motivate
them (bottom up), rather than explain them (top down). (I found ["You Could
Have Invented
Monads"](http://blog.sigfpe.com/2006/08/you-could-have-invented-monads-and.html)
extremely helpful when I was first getting to know monads, so this is my homage
to that post.) So without further ado...

# The Problem: callbacks are terrible

In any language, some things are just slow -- like writing to a file, or
sending a request over the network. JavaScript is single-threaded, so it can't
afford to pause the whole app while waiting for a single network response.
Instead, it handles these slow things by using asynchronous functions. An
asynchronous function is just like a normal function, except the caller doesn't
wait for it to return before moving on.  What does that mean for the code we
write? For one thing, it means that asynchronous functions can no longer return
a value to the caller, since the caller doesn't exist by the time the return
value would. So, instead of returning values, we pass them forward -- into a
function that was provided by the caller. (Such a function is called a
"callback", since it's the way for the asynchronous function to "call back"
into the main application code.) For example:

{% highlight javascript %}
function makeAnAsyncCall(param) {
    getFoo(param, (foo) => {
        // All logic for *after* the asynchronous call
        // goes in here, the callback.
    });
    // getFoo can't return its result, so there's no
    // point to having code here.
}
{% endhighlight %}

Another quirk of asynchronous functions is that they don't work well with
JavaScript's error-handling model either: since the caller has already
returned, there's no way to catch any exception that could be thrown by the
callee. Therefore, asynchronous functions shouldn't throw exceptions -- they
should indicate errors via some other means. Node.js's asynchronous functions
do this by passing an extra `err` parameter to every callback; this is called
"nodeback" style. (Another way of handling this, which Chrome's asynchronous
APIs take, is to put the error into a global variable which should be checked
after every asynchronous function call.) Using the nodeback style, our example
now looks like:

{% highlight javascript %}
function makeAnAsyncCall(param) {
    getFoo(param, (err, foo) => {
        // Now before we do anything with `foo`, we
        // need to make sure no error occurred, by
        // checking `err`.
    });
}
{% endhighlight %}

Fine, we can work with this -- and this was just "the way it was" for a while.
But this isn't ideal. To see why, let's look at an example. Suppose
we have some parameter, and we want to fetch some object `foo` using that
parameter, then fetch an object `bar` using the parameter and the `foo`, and
finally return both the `foo` and the `bar`. If this code were synchronous, it
could look like this:

{% highlight javascript %}
function getFooAndBar(param) {
    const foo = getFoo(param);
    const bar = getBar(param, foo);
    return {foo, bar};
}
{% endhighlight %}

But since `getFoo` and `getBar` will (hypothetically) do fetches over the
network, they'll be asynchronous, and might fail. That means we have to rewrite
it to look like this:

{% highlight javascript %}
function getFooAndBar(param, callback) {
    getFoo(param, (err, foo) => {
        if (err) return callback(err, null);
        getBar(param, foo, (err, bar) => {
            if (err) return callback(err, null);
            callback(null, {foo, bar});
        });
    });
}
{% endhighlight %}

What's wrong with this code? Two different factors make it hard to see what the
actual business logic is:

**Error forwarding.** It's annoying to have to remember to check for errors
after every asynchronous function call, and manually pass them to the callback.
There are two lines whose only job is to abort this part of the pipeline if
anything has gone wrong -- that distracts from the rest of the code. It would
be better if that were the default behavior, without our needing to specify it
explicitly.

**Nesting**. If we write a nested sequence of asynchronous functions (e.g. the
above sequence of 2 calls), the code drifts further and further to the right on
our screens. We could avoid this problem by writing every step of our sequence
as a standalone function, but this solution isn't ideal because it pollutes the
namespace of functions. Readers would be forced to hunt for function
definitions while trying to understand the main pipeline, which adds to the
cognitive load. It also forces developers to come up with a meaningful name
when writing each of those functions. That may not seem like a big deal, but
it's *hard* to name things meaningfully -- in fact it's one of the infamous
[two hard things in computer
science](https://martinfowler.com/bliki/TwoHardThings.html). It would be better
if we could write the code in a single function, but avoid nesting somehow.

## The Solution - part 1

Both of the above problems[^problems] can be solved, with enough engineering
work. This work has culminated in a class called a
[Promise](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise).
A `Promise` is an object that represents a value that may eventually be
computed; it can be thought of as a single-element container that may
eventually be filled.

Every `Promise` is in one of three states: "pending", meaning the computation
hasn't completed yet; "resolved", meaning the computation has finished
successfully and returned a value; and "rejected", meaning that the computation
failed, and threw an error.

There are other blog posts on what `Promise` best
practices are, how to use them effectively, etc.; this post won't do that.
Instead, I'll just show that `Promise`s let us write code that is free from the
above pain points, and move on. (In the following code snippets, we assume that
`getFoo` and `getBar` have be rewritten to return `Promise`s.)

**The Good.** Promises keep track of errors as control flow moves through the
sequence of asynchronous functions (henceforth referred to as the pipeline): as
soon as an error occurs, the promise is rejected, and won't call any more
callbacks until the error is handled somehow. So, it's no longer necessary to
check for errors and forward them along yourself. The 9-line example above
would become:

{% highlight javascript %}
function getFooAndBar(param) {
    return getFoo(param).then((foo) =>
        getBar(param, foo).then((bar) =>
             ({foo, bar})));
}
{% endhighlight %}

Look at that! No explicit error forwarding. Beautiful. We're still using
anonymous functions (e.g. `(bar) => ({foo, bar})`) to dictate what our
application's behavior should be, but notice that we're able to return things
again, even though the code is asynchronous. That's nice, because it lets us
write more "straightforward-looking" code, instead of passing around callbacks
everywhere. Now, how does error handling work?

{% highlight javascript %}
function processFooAndBar(param) {
    return getFooAndBar(param).then(({foo, bar}) => {
        if (!validateBar(bar)) {
            throw new Error("Invalid bar!");
        }
        // More logic...
    }).catch((err) => {
        // Any errors from getting the foo and bar, or
        // validating the bar, come here.
    });
}
{% endhighlight %}

That looks ok -- we can handle all the errors in one place, as long as they
occurred somewhere in the `Promise` pipeline. But...

**The ugly.** We still have nesting problems. In the `getFooAndBar` example
above, the final return value (`{foo, bar}`) needs `foo` to be in scope, so we
have to nest the callbacks, which we would like to avoid if possible.
Additionally, now we have implicit error forwarding, but we're still stuck
having two different ways of throwing and handling errors: using `try`/`catch`
blocks to catch errors that are thrown outside `Promise` pipelines, and calling
`.catch` on rejected `Promise`s to hande errors that are thrown inside
`Promise` pipelines. It would be nice if it didn't matter whether the error was
from something synchronous or asynchronous -- the syntax would be the same in
either case.

## The Solution - part 2

Promises don't require any baked-in language support (they're implemented in
terms of plain callbacks under the hood), but if we're going to solve these
last few ugly bits, the language (i.e. the browser's interpreter/compiler) has
to give us some help. What we want, ideally, is to be able to mostly ignore
whether a function was synchronous or asynchronous; we want them to look almost
identical. We want to avoid having towers of nested anonymous functions, and
having two different ways of handling and throwing errors.

One way to achieve this is to teach the language to understand promises. The
language will provide a way to "pause" a function until a given promise
resolves, and it'll provide a way to handle promises that reject along the way.
(Of course, the function wouldn't *really* pause, since that would defeat the
purpose of the asynchronous call.) These are the ideas behind the
`async`/`await` feature in a new version of JavaScript (ES8). Without further
ado, let's see how it improves our running example:

{% highlight javascript %}
async function getFooAndBar(param) {
    const foo = await getFoo(param);
    const bar = await getBar(param, foo);
    return {foo, bar};
}
{% endhighlight %}

That. Is. Beautiful. No explicit error-forwarding, no more nesting. The code
looks like it's synchronous again, except for those `async` and `await`
keywords. There's nothing left to distract from the business logic. But what
does the error-handling look like?

{% highlight javascript %}
async function processFooAndBar(param) {
    try {
        const {foo, bar} = await getFooAndBar(param);
        if (!validateBar(bar)) {
            throw new Error("Invalid bar!");
        }
    } catch(err) {
        // Any errors from getting the foo and bar, or
        // validating the bar, come here.
    }
}
{% endhighlight %}

Synchronous errors and asynchronous errors are now syntactically identical --
awesome. We no longer need to be distracted from the business logic, and can
depend on the language to make error handling easy.

# Promises: Origin Story

Now for the fun part. At this point, we should be asking ourselves: can we
solve other code-problems this nicely? Could the solutions look anything like
this?

The answers are yes and yes. In order to see why and what this has to do with
monads, let's switch languages, and switch problems slightly. We'll use
Haskell, and we'll imagine we have a bunch of functions that might fail.
Haskell has a data type that can represent an optional value; we'll use that as
a function's return type to indicate that the function might fail. The type's
definition looks like this:

{% highlight haskell %}
data Maybe a = Just a | Nothing
{% endhighlight %}

(In this definition, `a` is called a type parameter, and represents "any type".
You can think of it like the `<E>` in Java's generic collections, or in C++'s
templated classes.) The definition could be read aloud like this: "a `Maybe a`
is a data type that is either a `Just a` or a `Nothing`". Some example values
(and their types) are:

* `Just 3 :: Maybe Int`
* `Just 'c' :: Maybe Char`
* `Nothing :: Maybe a`

Ok, so we know what `Maybe`s look like. Let's do something with them! I'll pick
an example that looks suspiciously close to our JavaScript example, but instead
of being asynchronous *and* failure prone, this time it's just failure
prone.[^IO]

{% highlight haskell %}
-- The type signature: getFooAndBar takes a Param, and
-- produces a Maybe (Foo, Bar).
getFooAndBar :: Param -> Maybe (Foo, Bar)
-- The implementation: try getting the Foo, and if
-- successful, try getting the Bar, and if successful,
-- return Just (foo, bar).
getFooAndBar param = case getFoo param of
  Nothing -> Nothing
  Just foo -> case getBar param foo of
    Nothing -> Nothing
    Just bar -> Just (foo, bar)
{% endhighlight %}

Haskell looks a bit different from the JavaScript -- it has different syntax for
function definition and application, and it supports pattern matching and case
analysis. But overall that looks very familiar: we see the same problems of
manual error-forwarding and rightward drift as we did in the first JS callbacks
example. Let's find ways to fix those, one step at a time.

### The Solution - part 1

Our first goal is just to avoid repeating ourselves, and get a helper function
to do all the error forwarding. In other words, we want to design a pipeline
that, as soon as it detects something has returned `Nothing`, stops doing
anything until we explicitly handle the `Nothing`. We want there to be a
function that takes a value from the pipeline, and a way to transform that
value (if no error has happened yet), and produces the next value. I.e., it
takes a `Maybe a` and a function of type `a -> Maybe b`, and produces a `Maybe
b`. For the sake of evoking "pipeline" imagery (and for reasons that will be
revealed later), I'll implement this function as an infix function (aka an
operator) and call it `>>=`. (`>>=` kind of looks like a weird funnel to me.)
Here's what it could look like:

{% highlight haskell %}
(>>=) :: Maybe a -> (a -> Maybe b) -> Maybe b
ma >>= f = case ma of
  Nothing -> Nothing
  Just a -> f a
{% endhighlight %}

Pretty simple. This is the same kind of case analysis that we did before: it
examines `ma` and returns `Nothing` if `ma` is `Nothing`, but if it's `Just x`,
it returns the result of `f x`. So what did we just gain? Well, now we can use
it to rewrite our code this way: (Note: this uses Haskell's syntax for anonymous functions:
`\arg -> expr` is an anonymous function that takes an argument `arg`, and
evaluates to `expr`.)

{% highlight haskell %}
getFooAndBar :: Param -> Maybe (Foo, Bar)
getFooAndBar param =
  (getFoo param) >>= (\foo ->
    (getBar param foo) >>= (\bar ->
      Just (foo, bar)))
{% endhighlight %}

Not bad -- there's no more manual error forwarding, so we've solved the first
problem. But we still have nesting problems, just like in JavaScript. (At this
point, I encourage you to look back at the first `Promise` solution, and
compare it to this code.) Perhaps unsurprisingly, we'll need language-level
support to solve the nesting problem.

### The Solution - part 2

Ideally, we'd be able to express the same pipeline as above, without needing to
explicitly create the anonymous functions and funnel them through `>>=`.
Haskell provides this ability through something called "`do` notation". `do`
notation takes code written inside a "`do` block", and automatically rewrites
it to use `>>=` and anonymous functions instead. I'll show what I mean --
here's our familiar code, in its (almost) final form:

{% highlight haskell %}
getFooAndBar :: Param -> Maybe (Foo, Bar)
getFooAndBar param = do
  foo <- getFoo param
  bar <- getBar param foo
  Just (foo, bar)
{% endhighlight %}

In this version, I rewrote the `>>=` and anonymous functions as expressions
using `do` and `<-` instead -- and the compiler knows how to turn `do` and `<-`
back into `>>=` and anonymous functions. This is exactly equivalent to our
previous code, but no longer has any anonymous nested functions to worry about,
and no manual error forwarding. Just business logic.

### The Solution - part 3

Hopefully you're saying to yourself, "wait, hang on. How did the compiler know
how to rewrite our code? Is `Maybe` special? Was it because it used `>>=`?  Is
that a special symbol? This feels a bit too convenient." Great questions, and
you're right, this doesn't make sense yet, because I've omitted some details so
far.

In reality, the compiler only knows how to rewrite `do` blocks when they
produce data types for which it knows[^class] two particular functions (`>>=`
and `return`) are defined, and are defined in ways that satisfy certain rules.
For historical and mathematical reasons, these data types are called
["monads"](https://en.wikipedia.org/wiki/Monad_(category_theory)) (not that the
name really matters), and the rules are called the ["monad
laws"](https://en.wikipedia.org/wiki/Monad_(functional_programming)#Monad_laws).
As we saw, `>>=` takes a "context" data type (`Maybe`, in our case), and uses
another function to produce another of the same context data type, holding
something else. `return` takes a normal value and puts it in a "minimal"
version of that context type. (In the case of `Maybe`, there's only one way
to put a value in the context -- by using `Just`.) The full, real code
(including the `Monad` instance for `Maybe`, which defines `>>=` and `return`)
for our example is the following:

{% highlight haskell %}
instance Monad Maybe where
  ma >>= f = case ma of
    Just a -> f a
    _ -> Nothing

  return x = Just x


getFooAndBar :: Param -> Maybe (Foo, Bar)
getFooAndBar param = do
  foo <- getFoo param
  bar <- getBar param foo
  return (foo, bar)
{% endhighlight %}

That's it! The compiler now knows that `Maybe` is a monad[^maybe], so it knows we're
allowed to use "`do` notation" with it. We can also use `return` instead of
`Just`, to avoid repeating the fact that we're working with `Maybe`s.

At this point, it's clear `Promise`s and `async`/`await` are the same thing as
`Maybe`s and "`do` notation"! `Promise`s are just a different
monad[^promise-monad] -- one that combines "this might fail for some reason"
with "this may happen in the future". It may seem like monads are really good
at handling functions that may fail -- and it's true, they are. But monads are
good at composing *any* kind of "special" functions together in a pipeline.
Just as there are all kinds of "special" functions (e.g., functions that may
fail, functions that read from an environment, functions that also produce a
log of what they did, ...), there are all kinds of monads, and they are
extremely useful in practice (not just in academia!).

### Nondeterminism

Just to illustrate that all kinds of different things are monads, let's look at
another (slightly contrived) example problem, one that's totally different.
Suppose we have a bunch of files that should be named according to a pattern:
each name is a prefix (from a list of known prefixes) followed by a number 0-9.

One question we can ask is, given the list of prefixes, what are all the
possible filenames? Here's one way we could generate a list of these values in
JavaScript:

{% highlight javascript %}
function genFilenames(prefixes) {
    const filenames = [];
    for (const prefix of prefixes) {
        for (let i = 0; i <= 9; ++i) {
            filenames.push(prefix + i.toString());
        }
    }
    return filenames;
}
{% endhighlight %}

But since we're talking about pipelines of functions, let's write this in a
more functional style[^helpers]:

{% highlight javascript %}
function genFilenames(prefixes) {
    return flatten(
        prefixes.map((prefix) =>
            range(0, 9).map((i) =>
                prefix + i.toString())));
}
{% endhighlight %}

Just to make this look a little neater, I'll add a method to the `Array` class that
combines `flatten` and `map`:

{% highlight javascript %}
Array.prototype.flatMap = function(f) {
    return flatten(this.map(f));
}

function genFilenames(prefixes) {
    return prefixes.flatMap((prefix) =>
            range(0, 9).map((i) =>
                prefix + i.toString())));
}
{% endhighlight %}

Hmm. I see some familiar structure emerging... What does it look like if we
make both calls to `map` use `flatMap`, instead of just one?

{% highlight javascript %}
function genFilenames(prefixes) {
    return prefixes.flatMap((prefix) =>
        range(0, 9).flatMap((i) =>
            [prefix + i.toString()])));
}
{% endhighlight %}

Ok, that definitely looks familiar - it has the same structure of anonymous
functions that we had in our first `Promise` solution. Let's break out some
Haskell to see what we can do with this. (Note: Haskell's `concatMap` is
similar to our JS `flatMap`, and Haskell's `[0..9]` is the same as our
`range(0, 9)`.)

{% highlight haskell %}
genFilenames :: [String] -> [String]
getFooAndBar prefixes =
    concatMap (\prefix -> concatMap (\i -> [prefix ++ show i]) [0..9]) prefixes
{% endhighlight %}

Hmm, not super easy to see any parallel structure there. Let's rearrange things
and see if we can make it mirror the JavaScript better. One thing we'll do is
write a new function, `flatMap`, that's exactly like `concatMap` except the order
of the arguments is switched.  Next, Haskell allows any function to be called
as an infix operator, just by surrounding it with backticks (``); we'll use that so
we can put `flatMap` between the list and the anonymous function. Voila:

{% highlight haskell %}
flatMap :: [a] -> (a -> [b]) -> [b]
flatMap as f = concatMap f as

genFilenames :: [String] -> [String]
getFooAndBar prefixes =
    prefixes `flatMap` (\prefix ->
        [0..9] `flatMap` (\i ->
            [prefix ++ show i]))
{% endhighlight %}

At this point we have the same structure we had in JavaScript, which looked so
similar to the `Promise`s and `Maybe`s from before. If we squint and imagine we
had called `flatMap` `>>=` instead, this looks the same as our code for
`Maybe`, using its `Monad` instance. That suggests that maybe this is another
monad! Could we write a monad instance for this, so we could use `do` notation?
We'd need implementations of `>>=` and `return` -- let's think about what those
could be.

`>>=` should take a list of elements, and a function that turns an element into
a list of another kind of element, and should return a list of the new kind of
element.  In other words, the type signature should be `(>>=) :: [a] -> (a ->
[b]) -> [b]`. That's the same signature as `flatMap`, so that matches our
intuition so far! (Spoiler: another name for `>>=` is `bind`, but some people
also call it `flatMap`.)

What about `return`? `return` is supposed to take an element and put it in a
"minimal" context. The most minimal list context you can put an element into is
an empty list, so `return x` must just be `[x]` -- a list with only one element
in it. That's what we did with `[prefix ++ show i]`, so that matches our
intuition too.

The next step is to check and make sure these
definitions follow the monad laws, but I'll spare you the suspense -- they do.
So what does this look like in `do` notation?

{% highlight haskell %}
genFilenames :: [String] -> [String]
getFooAndBar prefixes = do
    prefix <- prefixes
    i <- [0..9]
    return (prefix ++ show i)
{% endhighlight %}

We can read this in the following way: "Choose some `prefix` from `prefixes`,
then choose some `i` from the range, and combine them in a certain way." In
other words, we've just discovered that the list monad can be used to compose
functions that produce multiple possible answers (i.e. that simulate
nondeterminism).[^comprehensions]

# What's the point?
![But Why?]({{ "/images/but_why.gif" | absolute_url }})

We've come a long way from writing callbacks in JavaScript. We've seen that
`Promises` and `async`/`await` provide a really nice way to solve the pain
points of asynchronous programming in JavaScript, and that Haskell's `do`
notation and monads lead us to a similar solution to a similar problem in
Haskell. But we've also seen that the same code patterns arise in other
situations, and monad instances can give us a nice layer of abstraction over
those as well.

Hopefully this post has demystified monads a bit, and illustrated that they're
just a generic way of composing "fancy" functions into pipelines, without
drowning in boilerplate.

---

[^problems]:
    I've listed two code problems here, but there are a bunch more that I'm not
    listing. For example, what if you have `n` asynchronous functions that you
    want to call, and then do something when they're *all* finished? That's
    difficult (but not impossible) to do with callbacks. Similarly, what if you
    had `n` asynchronous functions to call, and you want to see which one
    finishes first?  That's less difficult, but no less annoying, to do with
    callbacks. And -- did you remember to forward errors (correctly) in each of
    those previous scenarios?

[^IO]:
    If a function returns a type other than `IO a`, Haskell's type system
    prevents that function from doing things that have side effects. That
    includes things like reading from a file or fetching something over the
    network. So, these examples look pretty similar to the JavaScript examples
    that fetched over the network, but we know that that's a superficial
    similarity.

[^class]:
    In order to make the compiler aware that something is a monad, we must
    declare the data type as an instance of the `Monad` typeclass, and give the
    required function definitions.

[^maybe]:
    Of course, since `Maybe` and `Monad` are provided in Haskell's Prelude, in
    practice `Maybe`'s `Monad` instance is already [written for
    us](http://hackage.haskell.org/package/base-4.10.1.0/docs/src/GHC.Base.html#line-729).

[^promise-monad]:
    `Promise`s *technically* aren't a monad, because `promise.then(f)` (the
    equivalent of `ma >>= f`) doesn't quite satisfy the monad laws.
    (Specifically, it's impossible to create a `Promise` that contains another
    `Promise`, so the first monad law is violated sometimes.) But it's close
    enough to still be really nice to use.

[^helpers]:
    The helper functions used here are defined as follows:

        function range(start, end) {
            // Creates a list of integers in [start, end].
            const list = [];
            for (let i = start; i <= end; ++i) {
                list.push(i);
            }
            return list;
        }

        function flatten(lists) {
            // Flattens a list of lists into a single list.
            return lists.reduce((acc, list) =>
                acc.concat(list), []);
        }

[^comprehensions]:

    It's worth noting that the list monad is so useful that it has its own syntax
    sugar, called ["list
    comprehensions"](https://en.wikipedia.org/wiki/List_comprehension). List
    comprehensions have been included in some imperative languages (e.g. Python)
    simply because they are so convenient. Here's what a list comprehension would
    look like in Haskell:

        genFilenames :: [String] -> [String]
        getFooAndBar prefixes =
            [prefix ++ show i | prefix <- prefixes, i <- [0..9]]

    List comprehensions get their syntax from set notation in mathematics. The
    above example could be read, "`getFooAndBar prefixes` is a list of `prefix ++
    show i`, where `prefix` is an element of `prefixes`, and `i` is an element of
    `[0..9]`".

    (Aside: I personally prefer the list comprehension code and the monadic code
    over the original JavaScript version with nested for loops, but for a code
    snippet of this size and complexity, it doesn't make much of a difference. The
    real benefit comes when the pipeline gets longer and more complex, with more
    transformations and filters of the enumerated elements. Of course, an efficient
    implementation [via an optimizing compiler or an interpreter] is important if
    performance is a concern; but I contend that doing this optimization should be
    the tool's responsibility, not the programmer's.)